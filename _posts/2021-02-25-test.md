---
title:  테스트용으로 글과 이미지, 수식, 코드를 모두 넣어봤습니다.
tags:
  - Test
images:
---

세상엔 다양한 집들이 있을 것이다. 이 집들을 x축은 집의 면적, y축은 집의 가격에 해당하는 직교 좌표 위에 데이터로 나타난다고 가정해보자.
<!--more-->

## <span style="line-height:160%; color:#7f71ad; font-family: 'Noto Serif KR';">**· Lecture 2.1 - Linear Regression With One Variable**</span>

대략적으로 양의 상관관계가 있는 그래프가 나올 것이다. 여기서 집의 면적과 가격 두 값에 대한 학습을 한다고 가정하자.<br>

&nbsp;&nbsp;&nbsp;&nbsp;사전에 수집한 집값 정보라는 정답이 존재하므로 supervised learning에 해당하며, 추정하고자 하는 값이 실수값이므로 regression problem이다. 만약 일차함수에 비슷한 직선 그래프가 나온다면 linear regression problem이 된다.

<center>m: # of training examples</center>
<center>x’s = “input” variable / features</center>
<center>y’s = “output” variable / “target” variable</center>
로 정의되었을 때,

<center>(x, y) - one training example<br></center>
<center>(x<sup>(i)</sup>, y<sup>(i)</sup>) - i<sub>th</sub> training example</center>
와 같은 방식으로 접근할 수 있다.

&nbsp;&nbsp;&nbsp;&nbsp;일단 기본 구조는 training set에 대해, 알고리즘을 도출하여 알맞는 가설(hypothesis)을 만들고 검증하는 것이다. 여기서 x값은 집의 면적, y값은 집의 가격이 될 것이다. 가설은 x값으로부터 y값을 도출하는 특정 식이 될 것이다.

&nbsp;&nbsp;&nbsp;&nbsp;그렇다면 우리는 가설을 어떻게 세우는가? 가설은 어떤 형태의 함수로도 가능하지만, 일단 선형함수가 가장 많이 쓰인다.<br>
<center>$h_{θ}(x) = θ_{0}+θ_{1}x$ 와 같이 말이다.</center><br>

## <span style="line-height:160%; color:#7f71ad; font-family: 'Noto Serif KR';">**· Lecture 2.2 - Cost Function**</span>

&nbsp;&nbsp;&nbsp;&nbsp;가설을 $$h_{θ}(x) = θ_{0}+θ_{1}x$$와 같은 선형함수로 세웠다고 치자. 그러면 우리는 이 가설이 잘 맞아떨어지는 지 어떻게 확인할 수 있을까?
일단 여기서 $$θ_{1}$$, $$θ_{2}$$이 두 변수(parameter)로써 존재하므로, 이들에 대한 타당성이 증명되어야 할 것이다. 그리고 이를 평가할 수 있는 수치가 바로 cost function이다.



&nbsp;&nbsp;&nbsp;&nbsp;아래 식들은 cost function을 구하는 과정이다. 핵심 아이디어는 $$θ_{i}$$를 잘 골라서 $$h_{θ}(x)$$이 $$y$$에 가깝게 하는 것이다. $(1)$ 한 sample에서 sample값($y$)과 가설값($x$)의 차이를 수치화하고
 $(2)$ 이를 sample 수 만큼 더한 뒤
 $(3)$ sample 수 만큼 나누어서 평균을 구한다. 2를 더 나눈 것은 수학적 편의를 위한 것이라고 한다.


$$(h_{θ}(x)-y)^2\label{basic01}\tag{1}$$
$$\sum\limits_{i=1}^{m}{(h_{θ}(x^{(i)})-y^{(i)})^2}\tag{2}$$ 
$$cost function = \left(\cfrac{1}{2m}\right)\sum\limits_{i=1}^{m}{(h_{θ}(x^{(i)})-y^{(i)})^2}\tag{3}$$ <br>




## <span style="line-height:160%; color:#7f71ad; font-family: 'Noto Serif KR';">**· Lecture 2.3 - Cost Function Intuition**</span>


&nbsp;&nbsp;&nbsp;&nbsp;직관적인 접근을 위해 $θ_{0}$를 $0$으로 두면, $h_{θ}(x) = θ_{1}x$ 이다. 목표도 $J(θ_{1})$를 최소화하는 것이 된다. 가로축을 $θ_{1}$, 세로축을 $J(θ_{1})$으로 한 그래프를 그린다면, 아래로 볼록한 그래프가 그려지게 되는데,
여기서 $J(θ_{1})$값이 최소가 되는 지점이 바로 Cost function이 가장 최소인, 즉 가장 잘 들어맞는 가설 지점이 되는 것이다.<br>

## <span style="line-height:160%; color:#7f71ad; font-family: 'Noto Serif KR';">**· Lecture 2.4 - Cost Function 그래프 그리기**</span>


&nbsp;&nbsp;&nbsp;&nbsp;Google colab을 이용해 cost function 관련 코딩을 해봤습니다.<br>
&nbsp;&nbsp;&nbsp;&nbsp;(1,1), (2,2), (3,3) 총 3개의 값이 있다면, 쉽게 x=y 형태의 linear regression임을 알 수 있을 것입니다. $$h_{θ}(x) = θ_{0}+θ_{1}x$$에서
$$θ_{1}$$ 값은 1, $$θ_{0}x$$ 값은 0이 됩니다. 가로축이 $$θ_{1}$$이고, 세로축이 cost function인 그래프가 있다면 $$θ_{1}$$의 최솟값이 1이 되는 형태의 그래프가 나올 것입니다.


&nbsp;&nbsp;&nbsp;&nbsp;코드는 아래와 같습니다. 저는 google colab을 사용해서 plot을 바로 다운받는 형태로 작성했습니다.

```python
import tensorflow as tf
import matplotlib.pyplot as plt
from google.colab import files
X = [1,2,3]
Y = [1,2,3]

W = tf.placeholder(tf.float32)
#tf.placeholder는 데이터가 저장되는 공간, float32는 변수의 데이터 타입

hypothesis = X*W

cost = tf.reduce_mean(tf.square(hypothesis - Y))

sess = tf.Session()
#Session 객체는 중간 결과를 저장, 최종 결과를 작업 환경으로 전송하는 역할

sess.run(tf.global_variables_initializer())
#Session 객체 내의 run()을 통해 그래프 실행, 변수 초기화

W_val = []
cost_val = []
#그래프의 x축, y축 생성

for i in range(-30, 50):
  feed_W = i*0.1 #feed_W가 0.1 rksrurdmfh -3에서 5까지 움직입니다.
  curr_cost, curr_W = sess.run([cost, W], feed_dict = {W: feed_W}) 
  W_val.append(curr_W)
  cost_val.append(curr_cost)

plt.plot(W_val, cost_val)
plt.xlabel("$θ_1$")
plt.ylabel('cost')
plt.savefig('test.png', dpi = 300)
files.download('test.png')
```

<span style="display:block;text-align:center">![tansex1](/assets/images/posts/2021-02-25-test/tensex1.png){:width="60%"}</span>

*<center>위와 같이 최솟값이 1이 되는 그래프가 잘 나오는 것을 확인했습니다!</center>*

$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$
$$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$$
$$θ_{1}$$
$θ_{1}$

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script>
<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>